{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "os.getcwd()\n",
    "temporal_network = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "class YooChooseBinaryDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(YooChooseBinaryDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['adjacency_matrix.npy']\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['processed.dat']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        for raw_path in self.raw_paths:\n",
    "            # Read data from `raw_path`.\n",
    "            temporal_network = np.load(raw_path).squeeze().T[:, :100,:100]\n",
    "            for network in temporal_network:\n",
    "                df = pd.DataFrame(network)\n",
    "                df = df.stack().reset_index()\n",
    "\n",
    "                edge_list = np.array(df[['level_0', 'level_1' ]]).T            \n",
    "                edge_index = torch.tensor(edge_list, dtype=torch.long)\n",
    "\n",
    "                x = torch.zeros(100)\n",
    "                data = Data(x=x, edge_index=edge_index, y=x)\n",
    "                data_list.append(data)\n",
    "        \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        \n",
    "        \"\"\"\n",
    "        # process by session_id\n",
    "        grouped = df.groupby('session_id')\n",
    "        for session_id, group in tqdm(grouped):\n",
    "            sess_item_id = LabelEncoder().fit_transform(group.item_id)\n",
    "            group = group.reset_index(drop=True)\n",
    "            group['sess_item_id'] = sess_item_id\n",
    "            node_features = group.loc[group.session_id==session_id,['sess_item_id','item_id']].sort_values('sess_item_id').item_id.drop_duplicates().values\n",
    "\n",
    "            node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
    "            target_nodes = group.sess_item_id.values[1:]\n",
    "            source_nodes = group.sess_item_id.values[:-1]\n",
    "\n",
    "            edge_index = torch.tensor([source_nodes,\n",
    "                                   target_nodes], dtype=torch.long)\n",
    "            x = node_features\n",
    "\n",
    "            y = torch.FloatTensor([group.label.values[0]])\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "            \"\"\" \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = YooChooseBinaryDataset(root='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = torch.LongTensor([10,2,3,4,4])\n",
    "#t.size()[0]\n",
    "#temporal_network = np.load('input/raw/adjacency_matrix.npy').squeeze().T[:, :100,:100]\n",
    "\n",
    "#embedding = torch.nn.Embedding(num_embeddings=2, embedding_dim=128)\n",
    "#d = dataset[0].x.type(torch.LongTensor)\n",
    "#print(d)\n",
    "#embedding(dataset[1].x.type(torch.LongTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10000], x=[100], y=[100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:30]\n",
    "val_dataset = dataset[30:60]\n",
    "test_dataset = dataset[60:]\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "batch_size= 1 #1024 ammar\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num_items = df.item_id.max() +1 \n",
    "num_items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_max = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n",
      "Batch(batch=[100], edge_index=[2, 10000], x=[100], y=[100])\n"
     ]
    }
   ],
   "source": [
    "for t_images in train_loader:\n",
    "    print(t_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
    "class SAGEConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SAGEConv, self).__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=False)\n",
    "        self.update_act = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]     \n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        \n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        x_j = self.lin(x_j)\n",
    "        x_j = self.act(x_j)\n",
    "        \n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "\n",
    "        new_embedding = torch.cat([aggr_out, x], dim=1)\n",
    "        \n",
    "        new_embedding = self.update_lin(new_embedding)\n",
    "        new_embedding = self.update_act(new_embedding)\n",
    "        \n",
    "        return new_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "class Chimera(nn.Module):\n",
    "    def __init__(self, K = 10, N = 100):\n",
    "        super(Chimera, self).__init__()\n",
    "        self.U = torch.randn(N, K, requires_grad= True)\n",
    "        self.V = torch.randn(K, N, requires_grad= True)\n",
    "        self.params = nn.ParameterList([nn.Parameter(self.U),nn.Parameter(self.V)])\n",
    "    \n",
    "    def forward(self, At):\n",
    "        output =  torch.mm(self.U , self.V)\n",
    "        return output\n",
    "    \n",
    "def mapping(x):\n",
    "    cache = {}\n",
    "    if x not in cache:\n",
    "        cache[x] = len(cache)\n",
    "    return cache[x]\n",
    "\n",
    "A = np.array([\n",
    "    [[1,0, 0],\n",
    "     [0,0, 1],\n",
    "     [0,1, 0]\n",
    "    ],\n",
    "    [[1,0, 0],\n",
    "     [1,0, 1],\n",
    "     [0,1, 0]\n",
    "    ],\n",
    "    [[1,0, 0],\n",
    "     [0,1, 1],\n",
    "     [0,1, 1]\n",
    "    ],\n",
    "    [[1,0, 0],\n",
    "     [0,0, 1],\n",
    "     [0,1, 0]\n",
    "    ],\n",
    "    [[1,0, 0],\n",
    "     [1,0, 1],\n",
    "     [0,1, 0]\n",
    "    ],\n",
    "    [[1,0, 0],\n",
    "     [0,1, 1],\n",
    "     [0,1, 1]\n",
    "    ]\n",
    "   ])\n",
    "\n",
    "def tree_estimate(U):\n",
    "    kmeans = KMeans(n_clusters=2, init='k-means++', n_init=100, max_iter=3000, tol=0.0001 )\n",
    "    labels = kmeans.fit_predict(U.detach().numpy().reshape((-1, U.detach().numpy().shape[-1])))\n",
    "    counts = np.bincount(np.array([mapping(l) for l in labels]))\n",
    "\n",
    "    if len(counts) > 0:\n",
    "        first_community = np.argmax(counts)\n",
    "        counts = np.bincount(np.delete(counts, first_community))\n",
    "        first_community = np.sum(np.where(labels == first_community, 1, 0))\n",
    "    if len(counts) > 0:\n",
    "        second_community = np.argmax(counts)\n",
    "        second_community = np.sum(np.where(labels == second_community, 1, 0))\n",
    "    else : \n",
    "        second_community = 0\n",
    "\n",
    "    ratio = 1 - ((first_community - second_community) / first_community)\n",
    "    return ratio\n",
    "\n",
    "A = torch.from_numpy(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,1,2,1,1,1,3,2,2,1])\n",
    "counts = np.bincount(a)\n",
    "\n",
    "first_community = np.argmax(counts)\n",
    "counts = np.bincount(np.delete(counts, first_community))\n",
    "second_community = np.argmax(counts)\n",
    "\n",
    "print(first_community , second_community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings = 1083, batch_size=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = SAGEConv(embed_dim, 100)\n",
    "        self.pool1 = TopKPooling(1, ratio=1)\n",
    "        self.lin1 = nn.Linear(128*100, 100)\n",
    "        self.lin1_act = nn.ReLU()\n",
    "        self.rec1 = nn.GRU(input_size = 100, hidden_size = 100,  batch_first =True)\n",
    "        self.rec1_act = nn.ReLU()\n",
    "        self.hidden_h0 = self.initial_h0()\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embed_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.y, data.edge_index, data.batch\n",
    "        print(x.shape)\n",
    "        x = self.item_embedding(x.type(torch.LongTensor))\n",
    "        x = x.squeeze(1)        \n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch,_, _= self.pool1(x, edge_index, None, batch) \n",
    "        x = torch.flatten(x)\n",
    "        \n",
    "        x = self.lin1(x)\n",
    "        x= self.lin1_act(x)\n",
    "        #x = self.rec1(x, self.hidden_h0)\n",
    "        \n",
    "        #x =self.rec1_act(x)\n",
    "        #self.hidden_h0 = x\n",
    "        \n",
    "        \n",
    "        ## insert\n",
    "        return x , edge_index\n",
    "    \n",
    "    def initial_h0(self):\n",
    "        h0 = torch.randn(2, 3, 20)\n",
    "        return h0bincount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings = 1083, batch_size=10):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = 100\n",
    "        self.conv1 = SAGEConv(embed_dim, 100)\n",
    "        self.pool1 = TopKPooling(1, ratio=1)\n",
    "        self.lin1 = nn.Linear(128*100, 100)\n",
    "        self.lin1_act = nn.ReLU()\n",
    "        self.rec1 = nn.GRU(input_size = 100, hidden_size = 1,  batch_first =True)\n",
    "        self.rec1_act = nn.ReLU()\n",
    "        self.hidden_h0 = self.initial_h0()\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embed_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.y, data.edge_index, data.batch\n",
    "        x = self.item_embedding(x.type(torch.LongTensor))\n",
    "        x = x.squeeze(1)        \n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch,_, _= self.pool1(x, edge_index, None, batch) \n",
    "        x = torch.flatten(x)\n",
    "        \n",
    "        x = self.lin1(x)\n",
    "        x= self.lin1_act(x)\n",
    "        \n",
    "        return x , edge_index\n",
    "    \n",
    "    def initial_h0(self):\n",
    "        h0 = torch.randn(2, 3, 20)\n",
    "        return h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings = 1083, batch_size=10):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lin0 = nn.Linear(100, 1)\n",
    "        self.lin0_act = nn.ReLU()\n",
    "        \n",
    "        self.lin0_1 = nn.Linear(100,1)\n",
    "        self.lin0_1_act = nn.ReLU()\n",
    "        \n",
    "        self.hidden_size = 100\n",
    "        self.conv1 = SAGEConv(embed_dim, 100)\n",
    "        self.pool1 = TopKPooling(1, ratio=1)\n",
    "        self.lin1 = nn.Linear(128*100, 100)\n",
    "        self.lin1_act = nn.ReLU()\n",
    "        self.rec1 = nn.GRU(input_size = 100, hidden_size = 100,  batch_first =True)\n",
    "        self.rec1_act = nn.ReLU()\n",
    "        self.hidden_h0 = self.initial_h0()\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embed_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.y, data.edge_index, data.batch\n",
    "        x = self.lin0(x)\n",
    "        x = x.squeeze()\n",
    "        x = self.lin0_act(x)\n",
    "        \n",
    "        \n",
    "        edge_index =edge_index.type(torch.FloatTensor).view(2,10000, 100)\n",
    "        edge_index = self.lin0_1(edge_index)\n",
    "        edge_index = self.lin0_1_act(edge_index)\n",
    "        edge_index = edge_index.squeeze()\n",
    "        \n",
    "        \n",
    "        x = self.item_embedding(x.type(torch.LongTensor))\n",
    "        x = x.squeeze(1)        \n",
    "        \n",
    "        edge_index = edge_index.type(torch.LongTensor)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "\n",
    "        #x, edge_index, _, batch,_, _= self.pool1(x, edge_index, None, batch) \n",
    "        \n",
    "        x = torch.flatten(x)\n",
    "        \n",
    "        x = self.lin1(x)\n",
    "        x= self.lin1_act(x)\n",
    "        \n",
    "        return x , edge_index\n",
    "    \n",
    "    def initial_h0(self):\n",
    "        h0 = torch.randn(2, 3, 20)\n",
    "        return h0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import networkx as nx\n",
    "for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, edge_index = model(data)\n",
    "        label = data.y.to(device)\n",
    "        #loss = crit(output , label.type(torch.FloatTensor))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor,target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=100):\n",
    "    encoder_edge_index = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = len(train_loader) #input_tensor.size(0)\n",
    "    target_length = len(train_loader) #target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    encoder_edge_indexes = torch.zeros(max_length, 2,10000,  device=device)\n",
    "    loss = 0\n",
    "\n",
    "    #for ei in range(input_length):\n",
    "    i = 0\n",
    "    for data in train_loader:\n",
    "        encoder_output, encoder_edge_index = encoder(data)\n",
    "        encoder_outputs[i] = encoder_output\n",
    "        encoder_edge_indexes[i] = encoder_edge_index\n",
    "        i+=1\n",
    "        \n",
    "    #decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_input = torch.tensor([[10000]], device=device)\n",
    "\n",
    "    decoder_edge_index = encoder_edge_indexes\n",
    "    decoder_outputs = []\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            batch = torch.tensor(100, device=device)\n",
    "            data = Data(y = encoder_outputs, edge_index = encoder_edge_indexes, batch = batch)\n",
    "            decoder_output, decoder_edge_index = decoder(data)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            batch = torch.randn(100, device=device)\n",
    "            data = Data(y = encoder_outputs, edge_index = encoder_edge_indexes, batch = batch)\n",
    "            decoder_output, decoder_edge_index = decoder(data)\n",
    "            \n",
    "            #, decoder_attention decoder_input,\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            #if decoder_input.item() == EOS_token:\n",
    "            #    break\n",
    "\n",
    "    tree_estimator = Chimera(K = 10, N = 100)\n",
    "    tree_estimator_criterion = nn.MSELoss()\n",
    "    tree_estimator_optimizer = torch.optim.Adam(tree_estimator.parameters(), lr = 0.01)\n",
    "    #do the tree estimation\n",
    "    if(len(decoder_outputs) > 0):\n",
    "        decoder_outputs = torch.stack(decoder_outputs)\n",
    "        #yhat = chimera(A[0])\n",
    "        #temporal_network = torch.from_numpy(temporal_network)\n",
    "        for i in range(2):\n",
    "            for a in decoder_outputs:\n",
    "                tree_estimator_optimizer.zero_grad()\n",
    "                UV = tree_estimator(a)\n",
    "        Us = tree_estimator.U\n",
    "        loss += tree_estimate(Us)\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    tree_estimator_optimizer.step()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        label = data.y.to(device)\n",
    "        loss = crit(output , label.type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu') #ammar\n",
    "encoder = Encoder(num_embeddings=100).to(device)\n",
    "decoder = Decoder(num_embeddings=100).to(device)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters() ,lr = 0.01)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters() ,lr = 0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "MAX_LENGTH= 100\n",
    "target_tensor = torch.ones(100).type(torch.FloatTensor)\n",
    "#train(dataset,target_tensor, encoder,decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def trainIters(input_tensor,target_tensor,encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIters(dataset,target_tensor,encoder, decoder, 750, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-42788a92938b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_losses' is not defined"
     ]
    }
   ],
   "source": [
    "plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            pred = model(data).detach().cpu().numpy()\n",
    "\n",
    "            label = data.y.detach().cpu().numpy()\n",
    "            predictions.append(pred)\n",
    "            labels.append(label)\n",
    "\n",
    "    if(len(predictions) > 0):\n",
    "        predictions = np.hstack(predictions)\n",
    "        labels = np.hstack(labels)\n",
    "        print('labels: ',labels)\n",
    "        print('predictions: ',predictions)\n",
    "        try:\n",
    "            return roc_auc_score(labels, predictions)\n",
    "        except ValueError: \n",
    "            print('roc_auc_score error')\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run(epochs):\n",
    "    train_losses = []\n",
    "    train_accs =  []\n",
    "    val_accs = []\n",
    "    test_accs =  []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loss = train()\n",
    "        train_acc = evaluate(train_loader)\n",
    "        #val_acc = evaluate(val_loader)    \n",
    "        #test_acc = evaluate(test_loader)\n",
    "\n",
    "        train_losses.append(loss)\n",
    "        #val_accs.append(val_acc)\n",
    "        #test_accs.append(test_acc)\n",
    "        \n",
    "        print('Epoch: {:03d}, Loss: {:.5f}, Train Auc: {:.5f}, Val Auc: {:.5f}, Test Auc: {:.5f}'.\n",
    "              format(epoch, loss, train_acc, 0, 0))# val_acc, test_acc))\n",
    "    \n",
    "    return train_losses, None, None #val_accs , test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for data in train_loader:\n",
    "    data = data.to(device)\n",
    "    output = model(data)\n",
    "    print(output)\n",
    "    label = data.y.to(device)\n",
    "    print(label)\n",
    "    #loss = crit(output, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#output.type(torch.LongTensor)\n",
    "crit(output , label.type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10000], y=[100])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def normal_values(train_losses):\n",
    "    norm1 = np.array(train_losses) / np.linalg.norm(train_losses)\n",
    "    #norm2 = normalize(np.array(train_losses)[:,np.newaxis], axis=0).ravel()\n",
    "    return norm1\n",
    "\n",
    "train_line, = plt.plot(normal_values(train_losses))\n",
    "train_line.set_label('training')\n",
    "#plt.plot(normal_values(val_accs))\n",
    "\n",
    "#test_accs_line, = plt.plot(normal_values(test_accs))\n",
    "#test_accs_line.set_label('test')\n",
    "\n",
    "#validation_line, = plt.plot(normal_values(val_accs))\n",
    "#validation_line.set_label('validation')\n",
    "#plt.plot(normal_values(val_accs))\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
